{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bunaUR5hBtDY"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,preprocessing,faiss,inference,file-conversion,pdf]==1.17.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DImNZZmwBvMg"
      },
      "outputs": [],
      "source": [
        "api_key  = \"sk-xxxxxxxxxxxxxxxxxxxxxxxx\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAVMuN_9NeG5"
      },
      "source": [
        "# Index Papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhDunznRCMIf"
      },
      "outputs": [],
      "source": [
        "# index papers\n",
        "\n",
        "from haystack.nodes import PreProcessor\n",
        "from haystack.document_stores import FAISSDocumentStore\n",
        "from haystack.utils import convert_files_to_docs\n",
        "from haystack.nodes import EmbeddingRetriever\n",
        "\n",
        "document_store = FAISSDocumentStore(embedding_dim=1536, sql_url=\"sqlite:///data/faiss_document_store.db\")\n",
        "\n",
        "\n",
        "# OpenAI EmbeddingRetriever\n",
        "retriever = EmbeddingRetriever(\n",
        "   document_store=document_store,\n",
        "   batch_size=8,\n",
        "   embedding_model=\"text-embedding-ada-002\",\n",
        "   api_key=api_key,\n",
        "   max_seq_len=1536\n",
        ")\n",
        "\n",
        "\n",
        "preprocessor = PreProcessor(\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=True,\n",
        "    clean_empty_lines=True,\n",
        "    split_by=\"sentence\",\n",
        "    split_length=7,\n",
        "    split_overlap=1,\n",
        "    split_respect_sentence_boundary=False,\n",
        ")\n",
        "\n",
        "doc_dir = \"data/pdfdata\"  # upload papers in pdf format here\n",
        "\n",
        "\n",
        "all_docs = convert_files_to_docs(dir_path=doc_dir)\n",
        "docs = preprocessor.process(all_docs)\n",
        "document_store.write_documents(docs)\n",
        "document_store.update_embeddings(retriever)\n",
        "\n",
        "document_store.save(index_path=\"data/faiss_document_store_index.faiss\", config_path=\"data/faiss_document_store_config.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlzuW0mTNYSm"
      },
      "source": [
        "# Search papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PyPIzzcN04W"
      },
      "outputs": [],
      "source": [
        "question = \"According to the author how conspiracy theories benefit populists?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "xsKgyIVnBN-v"
      },
      "outputs": [],
      "source": [
        "# load created in the previos step document store\n",
        "\n",
        "from haystack.document_stores import FAISSDocumentStore\n",
        "new_document_store = FAISSDocumentStore(faiss_index_path=\"data/faiss_document_store_index.faiss\", faiss_config_path=\"data/faiss_document_store_config.json\")\n",
        "\n",
        "# Check if the DocumentStore is loaded correctly\n",
        "assert new_document_store.faiss_index_factory_str == \"Flat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5KDwsfDNtOW"
      },
      "outputs": [],
      "source": [
        "# init EmbeddingRetriever\n",
        "from haystack.nodes import EmbeddingRetriever\n",
        "\n",
        "retriever = EmbeddingRetriever(\n",
        "   document_store=new_document_store,\n",
        "   batch_size=8,\n",
        "   embedding_model=\"text-embedding-ada-002\",\n",
        "   api_key=api_key,\n",
        "   max_seq_len=1536\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEoYnd5uovLD"
      },
      "outputs": [],
      "source": [
        "# finc relevant documents\n",
        "from haystack.nodes import PromptNode\n",
        "\n",
        "candidate_documents = retriever.retrieve(\n",
        "    query=question,\n",
        "    top_k=7\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "DkJg3b7U9BPk"
      },
      "outputs": [],
      "source": [
        "# answer question\n",
        "\n",
        "prompt_node = PromptNode(model_name_or_path=\"gpt-3.5-turbo\", api_key=api_key, default_prompt_template='question-answering-with-references')\n",
        "\n",
        "from haystack.pipelines import Pipeline\n",
        "\n",
        "pipe = Pipeline()\n",
        "pipe.add_node(component=prompt_node, name=\"prompt_node\", inputs=[\"Query\"])\n",
        "\n",
        "output = pipe.run(query=question, documents=candidate_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfZo4yie9BZo"
      },
      "outputs": [],
      "source": [
        "result = {\n",
        "    \"answers\" : output[\"answers\"][0].answer\n",
        "}\n",
        "\n",
        "papers = set()\n",
        "\n",
        "for i, d in enumerate(output[\"documents\"]):\n",
        "  s = d.content\n",
        "  cleaned_string = s.encode('ascii', 'ignore').decode('utf-8')\n",
        "  cleaned_string = cleaned_string.replace(\"\\n\", \" \").replace(\"\\x0c\", \" \")\n",
        "  papers.add(d.meta[\"name\"])\n",
        "  result[f\"Document {i +1}\"] = {\n",
        "      \"title\": d.meta[\"name\"],\n",
        "      \"citation\": cleaned_string\n",
        "  }\n",
        "\n",
        "  result[\"papers\"] = papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
